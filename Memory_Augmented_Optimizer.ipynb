{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision.datasets import FashionMNIST, MNIST, CIFAR10, SVHN\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.utils as vision_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "\n",
    "DEVICE = torch.device('cuda')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_to_device(dataset,device=None):\n",
    "    final_X, final_Y = [], []\n",
    "    for x, y in dataset:\n",
    "        final_X.append(x)\n",
    "        final_Y.append(y)\n",
    "    X = torch.stack(final_X)\n",
    "    Y = torch.tensor(final_Y)\n",
    "    if device is not None:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "    return torch.utils.data.TensorDataset(X, Y)\n",
    "\n",
    "\n",
    "def get_mnist_dl(batch_size_train=256, batch_size_eval=256, device=torch.device('cpu')):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    data_train = MNIST('./datasets', train=True, download=True, transform=transform)\n",
    "    data_train = switch_to_device(data_train, device=device)\n",
    "    data_train, data_valid = torch.utils.data.random_split(data_train, [55000,5000])\n",
    "    \n",
    "    data_test = MNIST('./datasets', train=False, download=True, transform=transform)\n",
    "    data_test = switch_to_device(data_test, device=device)\n",
    "    \n",
    "    train_dl = DataLoader(data_train, batch_size=batch_size_train, shuffle=True)\n",
    "    valid_dl = DataLoader(data_valid, batch_size=batch_size_eval, shuffle=False)\n",
    "    test_dl = DataLoader(data_test, batch_size=batch_size_eval, shuffle=False)\n",
    "    \n",
    "    return train_dl, valid_dl, test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Net(nn.Module):\n",
    "\n",
    "  def __init__(self, num_classes=10) -> None:\n",
    "    super().__init__()\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.fc1 = nn.Linear(28*28, 1024)\n",
    "    self.Relu1 = nn.ReLU()\n",
    "    self.fc2 = nn.Linear(1024, 1024)\n",
    "    self.Relu2 = nn.ReLU()\n",
    "    self.fc3 = nn.Linear(1024, 1024)\n",
    "    self.Relu3 = nn.ReLU()\n",
    "    self.fc4 = nn.Linear(1024, num_classes)\n",
    "    #self.softmax = nn.Softmax()\n",
    "\n",
    "\n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    x = self.flatten(x)\n",
    "    x = self.Relu1(self.fc1(x))\n",
    "    x = self.Relu2(self.fc2(x))\n",
    "    x = self.Relu3(self.fc3(x))\n",
    "    x = self.fc4(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Net(nn.Module):\n",
    "    def __init__(self, num_classes=10) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 26, kernel_size=5, stride=1, padding = 0)\n",
    "        self.maxpooling1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(26, 52, kernel_size=3, stride=1, padding = 0)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(52, 10, kernel_size=1, stride=1, padding=0)\n",
    "        self.maxpooling3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc_1 = nn.Linear(5*5*10, 1000)\n",
    "        self.fc_2 = nn.Linear(1000, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.maxpooling1(F.relu(self.conv1(x)))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.maxpooling3(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = self.fc_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(stats):\n",
    "\n",
    "  fig, (ax1, ax2) = plt.subplots(1,2,figsize=(7,3), dpi=110)\n",
    "  ax1.grid()\n",
    "  ax2.grid()\n",
    "\n",
    "  ax1.set_title(\"ERM loss\")\n",
    "  ax2.set_title(\"Valid Acc\")\n",
    "  \n",
    "  ax1.set_xlabel(\"iterations\")\n",
    "  ax2.set_xlabel(\"iterations\")\n",
    "\n",
    "  itrs = [x[0] for x in stats['train-loss']]\n",
    "  loss = [x[1] for x in stats['train-loss']]\n",
    "  ax1.plot(itrs, loss)\n",
    "\n",
    "  itrs = [x[0] for x in stats['valid-acc']]\n",
    "  acc = [x[1] for x in stats['valid-acc']]\n",
    "  ax2.plot(itrs, acc)\n",
    "\n",
    "  ax1.set_ylim(0.0, max(loss))\n",
    "  ax2.set_ylim(0.0, 1.05)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_acc(model, dl):\n",
    "  model.eval()\n",
    "  acc = []\n",
    "  for X, y in dl:\n",
    "    #acc.append((torch.sigmoid(model(X)) > 0.5) == y)\n",
    "    acc.append(torch.argmax(model(X), dim=1) == y)\n",
    "  acc = torch.cat(acc)\n",
    "  acc = torch.sum(acc)/len(acc)\n",
    "  model.train()\n",
    "  return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffer_decay(gradient_buffer, decay_rate = 0.9):\n",
    "    new_buffer = {}\n",
    "    for key in gradient_buffer:\n",
    "        new_buffer[key*decay_rate] = gradient_buffer[key]\n",
    "    del gradient_buffer\n",
    "    return new_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_aggregation(gradient_buffer, cur_gradient):\n",
    "    res = {}\n",
    "    num = len(gradient_buffer.keys())\n",
    "    if num == 0:\n",
    "        return cur_gradient\n",
    "    for key in gradient_buffer.keys():\n",
    "        for i in gradient_buffer[key].keys():\n",
    "            if i not in res.keys():\n",
    "                res[i] = gradient_buffer[key][i]\n",
    "            else:\n",
    "                res[i] += gradient_buffer[key][i]\n",
    "    \n",
    "    for i in cur_gradient.keys():\n",
    "        res[i] += cur_gradient[i]\n",
    "        res[i] /= (num + 1)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_aggregation(gradient_buffer, cur_gradient):\n",
    "    res = {}\n",
    "    num = len(gradient_buffer.keys())\n",
    "    if num == 0:\n",
    "        return cur_gradient\n",
    "    for key in gradient_buffer.keys():\n",
    "        for i in gradient_buffer[key].keys():\n",
    "            if i not in res.keys():\n",
    "                res[i] = gradient_buffer[key][i]\n",
    "            else:\n",
    "                res[i] += gradient_buffer[key][i]\n",
    "    \n",
    "    for i in cur_gradient.keys():\n",
    "        res[i] /= num\n",
    "        res[i] += cur_gradient[i]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, opt, train_dl, valid_dl, test_dl, criterion, max_epochs=20, use_forward_grad=False, num_forward_grad=1, use_memory_augmented=False, buffer_capacity=5, decay_rate = 0.9, aggregate_method = \"mean\"):\n",
    "    itr = -1\n",
    "    stats = {'train-loss' : [], 'valid-acc' : []}\n",
    "    if use_memory_augmented:\n",
    "        gradient_buffer = {}\n",
    "    random_dir = {}\n",
    "    for i, p in enumerate(model.parameters()):\n",
    "        random_dir[i] = 0\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        for x, y in train_dl:\n",
    "            itr += 1\n",
    "            '''\n",
    "            if itr != 0 and itr % 2000 ==0 :\n",
    "                if buffer_capacity < 400:\n",
    "                    buffer_capacity += 20\n",
    "            '''\n",
    "            opt.zero_grad()\n",
    "            loss = criterion(model(x), y)\n",
    "            loss.backward()\n",
    "            if use_memory_augmented:\n",
    "                norm = 0\n",
    "            if use_forward_grad:\n",
    "                temp_grad = {}\n",
    "                with torch.no_grad():\n",
    "                    da = torch.zeros((num_forward_grad, 1), device = DEVICE)\n",
    "\n",
    "                    for i, p in enumerate(model.parameters()):\n",
    "                        g = p.grad.view(-1)\n",
    "                        v = torch.randn(num_forward_grad, len(g), device=DEVICE)\n",
    "                        random_dir[i] = v\n",
    "                        da = da + (v @ g).view(num_forward_grad, 1)\n",
    "\n",
    "                    for i, p in enumerate(model.parameters()):\n",
    "                        g = (da * random_dir[i]).mean(dim = 0)\n",
    "                        if use_memory_augmented:\n",
    "                            norm += torch.norm(g)**2\n",
    "                        temp_grad[i] = g.view(p.grad.shape)\n",
    "\n",
    "                    if use_memory_augmented:\n",
    "                        aggregate_gradient = {}\n",
    "                        if aggregate_method == \"mean\":\n",
    "                            estimated_gradient = mean_aggregation(gradient_buffer, temp_grad)\n",
    "                        elif aggregate_method == \"sum\":\n",
    "                            estimated_gradient = sum_aggregation(gradient_buffer, temp_grad)\n",
    "                        gradient_buffer = buffer_decay(gradient_buffer, decay_rate)\n",
    "                        if len(gradient_buffer.keys()) < buffer_capacity:\n",
    "                            gradient_buffer[norm] = temp_grad\n",
    "                        else:\n",
    "                            min_norm = min(gradient_buffer.keys())\n",
    "                            if min_norm <= norm:\n",
    "                                del gradient_buffer[min_norm]\n",
    "                                gradient_buffer[norm] = temp_grad\n",
    "                    \n",
    "                    else:\n",
    "                        estimated_gradient = temp_grad\n",
    "                    \n",
    "                    for i, p in enumerate(model.parameters()):\n",
    "                        p.grad = estimated_gradient[i].view(p.grad.shape)\n",
    "            \n",
    "            opt.step()\n",
    "            stats['train-loss'].append((itr, loss.item()))\n",
    "\n",
    "            if itr % 100 == 0:\n",
    "                valid_acc = get_acc(model, valid_dl)\n",
    "                stats['valid-acc'].append((itr, valid_acc))\n",
    "                s = f\"{epoch}:{itr} [train] loss:{loss.item():.3f}, [valid] acc:{valid_acc:.3f}\"\n",
    "                print(s)\n",
    "    \n",
    "    test_acc = get_acc(model, test_dl)\n",
    "    print(f\"[test] acc:{test_acc:.3f}\")\n",
    "\n",
    "    return stats\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP_Net().to(DEVICE)\n",
    "opt = torch.optim.SGD(model.parameters(), lr = 1e-4)\n",
    "criterion =nn.CrossEntropyLoss()\n",
    "max_epochs = 300\n",
    "use_forward_grad = False\n",
    "num_forward_grad = 1\n",
    "use_memory_augmented = False\n",
    "buffer_capacity = 5\n",
    "decay_rate = 0.9\n",
    "aggregate_method = 'mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:0 [train] loss:17.984, [valid] acc:0.065\n",
      "0:100 [train] loss:7.241, [valid] acc:0.127\n",
      "0:200 [train] loss:4.751, [valid] acc:0.249\n",
      "1:300 [train] loss:4.002, [valid] acc:0.378\n",
      "1:400 [train] loss:3.374, [valid] acc:0.475\n",
      "2:500 [train] loss:2.364, [valid] acc:0.537\n",
      "2:600 [train] loss:2.389, [valid] acc:0.579\n",
      "3:700 [train] loss:1.888, [valid] acc:0.614\n",
      "3:800 [train] loss:2.011, [valid] acc:0.638\n",
      "4:900 [train] loss:1.675, [valid] acc:0.655\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/deyaoyux/Gitlab/forward-mode-autodiff/Memory_Augmented_Optimizer.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703031222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-autodiff/Memory_Augmented_Optimizer.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     v \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnormal(mean \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfull((\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(g)), \u001b[39m0.\u001b[39m), std \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfull((\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(g)), \u001b[39m0.1\u001b[39m))\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703031222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-autodiff/Memory_Augmented_Optimizer.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     p\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39mview(p\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703031222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-autodiff/Memory_Augmented_Optimizer.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m stats \u001b[39m=\u001b[39m run_experiment(model, opt, train_dl, valid_dl, test_dl, criterion, max_epochs, use_forward_grad, num_forward_grad, use_memory_augmented, buffer_capacity, decay_rate, aggregate_method)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703031222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-autodiff/Memory_Augmented_Optimizer.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m print_stats(stats)\n",
      "\u001b[1;32m/home/deyaoyux/Gitlab/forward-mode-autodiff/Memory_Augmented_Optimizer.ipynb Cell 11\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(model, opt, train_dl, valid_dl, test_dl, criterion, max_epochs, use_forward_grad, num_forward_grad, use_memory_augmented, buffer_capacity, decay_rate, aggregate_method)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703031222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-autodiff/Memory_Augmented_Optimizer.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m itr \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703031222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-autodiff/Memory_Augmented_Optimizer.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703031222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-autodiff/Memory_Augmented_Optimizer.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mif itr != 0 and itr % 2000 ==0 :\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703031222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-autodiff/Memory_Augmented_Optimizer.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m    if buffer_capacity < 400:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703031222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-autodiff/Memory_Augmented_Optimizer.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m        buffer_capacity += 20\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703031222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-autodiff/Memory_Augmented_Optimizer.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703031222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-autodiff/Memory_Augmented_Optimizer.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m opt\u001b[39m.\u001b[39;49mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703031222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-autodiff/Memory_Augmented_Optimizer.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(model(x), y)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703031222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-autodiff/Memory_Augmented_Optimizer.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/BNN/lib/python3.9/site-packages/torch/optim/optimizer.py:255\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39mfor\u001b[39;00m _, per_dtype_grads \u001b[39min\u001b[39;00m per_device_and_dtype_grads\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    254\u001b[0m     \u001b[39mfor\u001b[39;00m grads \u001b[39min\u001b[39;00m per_dtype_grads\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m--> 255\u001b[0m         torch\u001b[39m.\u001b[39m_foreach_zero_(grads)\n",
      "File \u001b[0;32m~/anaconda3/envs/BNN/lib/python3.9/site-packages/torch/autograd/profiler.py:451\u001b[0m, in \u001b[0;36mrecord_function.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc_type: Any, exc_value: Any, traceback: Any):\n\u001b[1;32m    450\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_callbacks_on_exit:\n\u001b[0;32m--> 451\u001b[0m         torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39m_record_function_exit(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl, test_dl = get_mnist_dl(device=DEVICE)\n",
    "\n",
    "for p in model.parameters():\n",
    "    g = p.view(-1)\n",
    "    v = torch.normal(mean = torch.full((1, len(g)), 0.), std = torch.full((1, len(g)), 0.1)).to(DEVICE)\n",
    "    p.data = v.view(p.shape)\n",
    "\n",
    "stats = run_experiment(model, opt, train_dl, valid_dl, test_dl, criterion, max_epochs, use_forward_grad, num_forward_grad, use_memory_augmented, buffer_capacity, decay_rate, aggregate_method)\n",
    "print_stats(stats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('BNN': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb840f806f29f410adf72128552a18fefb24267895bb11ac579fa6a12231d74f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
