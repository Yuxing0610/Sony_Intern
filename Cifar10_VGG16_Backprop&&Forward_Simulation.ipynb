{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This book is used to implement the VGG16 on Cifar-10 dataset, using the traditional backpropagation method and the simulationn approach for forward-mode autodiff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "DEVICE = torch.device('cuda')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_to_device(dataset,device=None):\n",
    "    final_X, final_Y = [], []\n",
    "    for x, y in dataset:\n",
    "        final_X.append(x)\n",
    "        final_Y.append(y)\n",
    "    X = torch.stack(final_X)\n",
    "    Y = torch.tensor(final_Y)\n",
    "    if device is not None:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "    return TensorDataset(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Cifar10_dl(batch_size_train=256, batch_size_eval=1024, device=DEVICE):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    data_train = CIFAR10('./datasets', train=True, download=True, transform=transform)\n",
    "    data_train = switch_to_device(data_train, device=device)\n",
    "    data_train, data_valid = torch.utils.data.random_split(data_train, [45000,5000])\n",
    "    \n",
    "    data_test = CIFAR10('./datasets', train=False, download=True, transform=transform)\n",
    "    data_test = switch_to_device(data_test, device=device)\n",
    "    \n",
    "    train_dl = DataLoader(data_train, batch_size=batch_size_train, shuffle=True)\n",
    "    valid_dl = DataLoader(data_valid, batch_size=batch_size_eval, shuffle=False)\n",
    "    test_dl = DataLoader(data_test, batch_size=batch_size_eval, shuffle=False)\n",
    "    \n",
    "    return train_dl, valid_dl, test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        '''\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        '''\n",
    "        '''\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        '''\n",
    "        self.fc = nn.Sequential(\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(8*8*256, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU())\n",
    "        self.fc2= nn.Sequential(\n",
    "            nn.Linear(1024, num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        #out = self.layer7(out)\n",
    "        '''\n",
    "        out = self.layer8(out)\n",
    "        out = self.layer9(out)\n",
    "        out = self.layer10(out)\n",
    "        out = self.layer11(out)\n",
    "        out = self.layer12(out)\n",
    "        out = self.layer13(out)\n",
    "        '''\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(stats):\n",
    "\n",
    "  fig, (ax1, ax2) = plt.subplots(1,2,figsize=(7,3), dpi=110)\n",
    "  ax1.grid()\n",
    "  ax2.grid()\n",
    "\n",
    "  ax1.set_title(\"ERM loss\")\n",
    "  ax2.set_title(\"Valid Acc\")\n",
    "  \n",
    "  ax1.set_xlabel(\"iterations\")\n",
    "  ax2.set_xlabel(\"iterations\")\n",
    "\n",
    "  itrs = [x[0] for x in stats['train-loss']]\n",
    "  loss = [x[1] for x in stats['train-loss']]\n",
    "  ax1.plot(itrs, loss)\n",
    "\n",
    "  itrs = [x[0] for x in stats['valid-acc']]\n",
    "  acc = [x[1] for x in stats['valid-acc']]\n",
    "  ax2.plot(itrs, acc)\n",
    "\n",
    "  ax1.set_ylim(0.0, max(loss))\n",
    "  ax2.set_ylim(0.0, 1.05)\n",
    "  fig.savefig('testing.jpg', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_acc(model, dl):\n",
    "  model.eval()\n",
    "  acc = []\n",
    "  for X, y in dl:\n",
    "    #acc.append((torch.sigmoid(model(X)) > 0.5) == y)\n",
    "    acc.append(torch.argmax(model(X), dim=1) == y)\n",
    "  acc = torch.cat(acc)\n",
    "  acc = torch.sum(acc)/len(acc)\n",
    "  model.train()\n",
    "  return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize(input):\n",
    "    mean = torch.mean(input, dim=1).view(-1, 1)\n",
    "    std = torch.std(input, dim=1).view(-1, 1)\n",
    "    return (input - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_proj_matrix(A):\n",
    "    return A @ torch.inverse(A.T @ A) @ A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, opt, schedular, criterion, train_dl, valid_dl, test_dl, max_epochs, use_forward_grad, num_dir, use_linear_projection, use_cnn_projection):\n",
    "    itr = -1\n",
    "    stats = {'train-loss' : [], 'valid-acc' : []}\n",
    "\n",
    "    if use_forward_grad:\n",
    "        random_dir = {}\n",
    "        for i, p in enumerate(model.parameters()):\n",
    "            random_dir[i] = 0\n",
    "    \n",
    "    if use_linear_projection or use_cnn_projection:\n",
    "        name_module = {}\n",
    "        layer_inputs = {}\n",
    "        def hook(mod, input):\n",
    "            layer_inputs[mod] = input[0]\n",
    "        for module in model.modules():\n",
    "            module.register_forward_pre_hook(hook)\n",
    "        for name, module in model.named_modules():\n",
    "            name_module[name] = module\n",
    "\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        for x, y in train_dl:\n",
    "            itr += 1\n",
    "            opt.zero_grad()\n",
    "            loss = criterion(model(x), y)\n",
    "            loss.backward()\n",
    "\n",
    "            if use_forward_grad:\n",
    "                with torch.no_grad():\n",
    "                    da = torch.zeros((num_dir, 1), device=DEVICE)\n",
    "                    '''\n",
    "                    for i, p in enumerate(model.parameters()):\n",
    "                        g = p.grad.view(-1)\n",
    "                        v = torch.randn(num_dir, len(g), device=DEVICE)#.sign()\n",
    "                        random_dir[i] = v\n",
    "                        da += (v @ g).view(num_dir, 1)\n",
    "                    '''\n",
    "                    for i, (name, parameters) in enumerate(model.named_parameters()):\n",
    "                        g = parameters.grad.view(-1)\n",
    "\n",
    "                        if len(parameters.shape) == 2 and use_linear_projection:\n",
    "                            input = layer_inputs[name_module[name[:name.find('.', name.find('.') + 1)]]]\n",
    "                            projection_matrix = cal_proj_matrix(input.T)\n",
    "                            input_sample = torch.randn(num_dir, parameters.shape[1], device = DEVICE).view(num_dir, parameters.shape[1], 1)\n",
    "                            input_sample = (projection_matrix @ input_sample).view(num_dir, 1, -1)\n",
    "                            v = torch.randn(num_dir, parameters.shape[0], device = DEVICE).view(num_dir, parameters.shape[0], 1)\n",
    "                            v = (v @ input_sample).view(num_dir, -1)\n",
    "\n",
    "                        elif len(parameters.shape) == 4 and use_cnn_projection:\n",
    "                            input = layer_inputs[name_module[name[:name.find('.', name.find('.') + 1)]]]\n",
    "                            shape_input = input.shape\n",
    "                            input = input.view(input.shape[0], -1)\n",
    "                            projection_matrix = cal_proj_matrix(input.T)\n",
    "                            input_sample = torch.randn(num_dir, input.shape[1], device = DEVICE).view(num_dir, input.shape[1], 1)\n",
    "                            input_sample = (projection_matrix @ input_sample).view(num_dir, shape_input[1], shape_input[2], shape_input[3])\n",
    "                            output_sample = torch.randn(num_dir, parameters.shape[0], shape_input[2], shape_input[3], device = DEVICE)\n",
    "                            v = torch.zeros(num_dir, parameters.shape[0], parameters.shape[1], parameters.shape[2], parameters.shape[3], device = DEVICE)\n",
    "                            for n in range(num_dir):\n",
    "                                for f in range(parameters.shape[0]):\n",
    "                                    v[n][f] = torch.nn.functional.conv2d(input_sample[n], output_sample[n][f].unsqueeze(0).unsqueeze(0).expand(parameters.shape[1], parameters.shape[1],shape_input[2], shape_input[3]), stride=1, padding=1)\n",
    "                            v = v.view(num_dir, -1)\n",
    "      \n",
    "                        else:\n",
    "                            v = torch.randn(num_dir, len(g), device=DEVICE)\n",
    "                        random_dir[i] = v\n",
    "                        da += (v @ g).view(num_dir, 1)\n",
    "\n",
    "                    \n",
    "                    for i, p in enumerate(model.parameters()):\n",
    "                        g = da * random_dir[i]\n",
    "                        p.grad = torch.mean(g, dim = 0).view(p.grad.shape)\n",
    "\n",
    "            opt.step()\n",
    "            if itr <= 10000:\n",
    "                schedular.step()\n",
    "            stats['train-loss'].append((itr, loss.item()))\n",
    "\n",
    "            if itr % 10 == 0:\n",
    "                valid_acc = get_acc(model, valid_dl)\n",
    "                stats['valid-acc'].append((itr, valid_acc))\n",
    "                s = f\"{epoch}:{itr} [train] loss:{loss.item():.3f}, [valid] acc:{valid_acc:.3f}\"\n",
    "                print(s)\n",
    "\n",
    "    test_acc = get_acc(model, test_dl)\n",
    "    print(f\"[test] acc:{test_acc:.3f}\")\n",
    "\n",
    "    return stats\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18989386\n"
     ]
    }
   ],
   "source": [
    "model = VGG16().to(DEVICE)\n",
    "print(count_parameters(model))\n",
    "\n",
    "train_batch_size = 128\n",
    "test_batch_size = 1024\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr = 1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=2500, gamma=0.5)\n",
    "criterion =nn.CrossEntropyLoss()\n",
    "max_epochs = 100\n",
    "\n",
    "use_forward_grad = True\n",
    "num_dir = 20\n",
    "use_linear_projection = True\n",
    "use_cnn_projection = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "0:0 [train] loss:2.381, [valid] acc:0.104\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/deyaoyux/Gitlab/forward-mode-bnn/Cifar10_VGG16_Backprop&&Forward_Simulation.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703139222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-bnn/Cifar10_VGG16_Backprop%26%26Forward_Simulation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_dl, valid_dl, test_dl \u001b[39m=\u001b[39m get_Cifar10_dl(train_batch_size, test_batch_size, device \u001b[39m=\u001b[39m DEVICE)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703139222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-bnn/Cifar10_VGG16_Backprop%26%26Forward_Simulation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m stats \u001b[39m=\u001b[39m run_experiment(model, opt, scheduler, criterion, train_dl, valid_dl, test_dl, max_epochs, use_forward_grad, num_dir, use_linear_projection, use_cnn_projection)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703139222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-bnn/Cifar10_VGG16_Backprop%26%26Forward_Simulation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m print_stats(stats)\n",
      "\u001b[1;32m/home/deyaoyux/Gitlab/forward-mode-bnn/Cifar10_VGG16_Backprop&&Forward_Simulation.ipynb Cell 13\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(model, opt, schedular, criterion, train_dl, valid_dl, test_dl, max_epochs, use_forward_grad, num_dir, use_linear_projection, use_cnn_projection)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703139222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-bnn/Cifar10_VGG16_Backprop%26%26Forward_Simulation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m     \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_dir):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703139222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-bnn/Cifar10_VGG16_Backprop%26%26Forward_Simulation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m         \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(parameters\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703139222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-bnn/Cifar10_VGG16_Backprop%26%26Forward_Simulation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m             v[n][f] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49mconv2d(input_sample[n], output_sample[n][f]\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mexpand(parameters\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], parameters\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m],shape_input[\u001b[39m2\u001b[39;49m], shape_input[\u001b[39m3\u001b[39;49m]), stride\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, padding\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703139222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-bnn/Cifar10_VGG16_Backprop%26%26Forward_Simulation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m     v \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39mview(num_dir, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703139222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-bnn/Cifar10_VGG16_Backprop%26%26Forward_Simulation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl, test_dl = get_Cifar10_dl(train_batch_size, test_batch_size, device = DEVICE)\n",
    "stats = run_experiment(model, opt, scheduler, criterion, train_dl, valid_dl, test_dl, max_epochs, use_forward_grad, num_dir, use_linear_projection, use_cnn_projection)\n",
    "print_stats(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('BNN': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb840f806f29f410adf72128552a18fefb24267895bb11ac579fa6a12231d74f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
