{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we truely implement the Forward-mode autodiff instead of only use the simulate version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision.datasets import FashionMNIST, MNIST, CIFAR10, SVHN\n",
    "from torch.autograd import Variable\n",
    "from torch import autograd\n",
    "import torch.autograd.forward_ad as fwAD\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.utils as vision_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "DEVICE = torch.device('cuda')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_to_device(dataset,device=None):\n",
    "    final_X, final_Y = [], []\n",
    "    for x, y in dataset:\n",
    "        final_X.append(x)\n",
    "        final_Y.append(y)\n",
    "    X = torch.stack(final_X)\n",
    "    Y = torch.tensor(final_Y)\n",
    "    if device is not None:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "    return torch.utils.data.TensorDataset(X, Y)\n",
    "\n",
    "\n",
    "def get_mnist_dl(batch_size_train=1024, batch_size_eval=1024, device=torch.device('cuda')):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    data_train = MNIST('./datasets', train=True, download=True, transform=transform)\n",
    "    data_train = switch_to_device(data_train, device=device)\n",
    "    data_train, data_valid = torch.utils.data.random_split(data_train, [55000,5000])\n",
    "    \n",
    "    data_test = MNIST('./datasets', train=False, download=True, transform=transform)\n",
    "    data_test = switch_to_device(data_test, device=device)\n",
    "    \n",
    "    train_dl = DataLoader(data_train, batch_size=batch_size_train, shuffle=True)\n",
    "    valid_dl = DataLoader(data_valid, batch_size=batch_size_eval, shuffle=False)\n",
    "    test_dl = DataLoader(data_test, batch_size=batch_size_eval, shuffle=False)\n",
    "    \n",
    "    return train_dl, valid_dl, test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(stats):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (6, 3), dpi = 110)\n",
    "    ax1.grid()\n",
    "    ax2.grid()\n",
    "\n",
    "    ax1.set_title(\"ERM loss\")\n",
    "    ax2.set_title(\"Valid Acc\")\n",
    "\n",
    "    ax1.set_xlabel(\"iterations\")\n",
    "    ax2.set_xlabel(\"iterations\")\n",
    "\n",
    "    itrs = [x[0] for x in stats['train-loss']]\n",
    "    loss = [x[1].cpu().detach().numpy() for x in stats['train-loss']]\n",
    "    ax1.plot(itrs, loss)\n",
    "\n",
    "    itrs = [x[0] for x in stats['valid-acc']]\n",
    "    acc = [x[1] for x in stats['valid-acc']]\n",
    "    ax2.plot(itrs, acc)\n",
    "\n",
    "\n",
    "    ax1.set_ylim(0.0, np.max(loss))\n",
    "    ax2.set_ylim(0.0, 1.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_acc(model, dl, num_dir, device = DEVICE):\n",
    "    acc = []\n",
    "\n",
    "    for X, y in dl:\n",
    "        #one_hot_y = torch.zeros((X.shape[0], 10), device = DEVICE)\n",
    "        #one_hot_y[[i for i in range(X.shape[0])], [k.item() for k in y]] = 1\n",
    "        model.forward(X, y, num_dir)\n",
    "        acc.append(torch.argmax(model.output, dim=1) == y)\n",
    "\n",
    "    acc = torch.cat(acc)\n",
    "    acc = torch.sum(acc)/len(acc)\n",
    "\n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这里现在用的还是最简单的binarize的方法\n",
    "def Binarize(x, quant_mode = 'det'):\n",
    "    if quant_mode == 'det':\n",
    "        return x.sign()\n",
    "    else:\n",
    "        return x.add_(1).div_(2).add_(torch.rand(x.size()).add(-0.5)).clamp_(0,1).round().mul_(2).add_(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "class self_BinarizeLinear(nn.Linear):\n",
    "\n",
    "    def __init__(self, *kargs, **kwargs):\n",
    "        super(self_BinarizeLinear, self).__init__(*kargs, **kwargs)\n",
    "    \n",
    "    def forward(self, num_dir, input, da = None):\n",
    "        '''\n",
    "        input: batchsize * input_size\n",
    "        da: None or num_dir * batchsize * input_size\n",
    "        '''\n",
    "\n",
    "        if input.size(1) != 784:\n",
    "            input.data = Binarize(input.data)\n",
    "        \n",
    "        #if torch.is_tensor(da):\n",
    "            #da = da.sign()\n",
    "        \n",
    "        self.vector_w = torch.randn((num_dir, self.weight.data.shape[0], self.weight.data.shape[1]), device = DEVICE).sign()\n",
    "        self.weight.data = Binarize(self.weight.data)\n",
    "        out = nn.functional.linear(input, self.weight)\n",
    "        if torch.is_tensor(da): \n",
    "            new_da = torch.matmul(da, self.weight.T) + torch.matmul(input, self.vector_w.transpose(1,2))\n",
    "        else:\n",
    "            new_da = torch.matmul(input, self.vector_w.transpose(1, 2))\n",
    "\n",
    "        if not self.bias is None:\n",
    "            self.vector_b = torch.randn((num_dir, 1, self.bias.shape[0]), device = DEVICE).sign()\n",
    "            self.bias.data = Binarize(self.bias.data)\n",
    "            out += self.bias.view(1,-1).expand_as(out)\n",
    "            new_da += self.vector_b\n",
    "        \n",
    "        return out, new_da\n",
    "    \n",
    "    def update(self, da, lr):\n",
    "        gw = da*self.vector_w\n",
    "        gw = torch.mean(gw, dim = 0)\n",
    "        self.weight.data -= lr*gw\n",
    "        self.weight.data = self.weight.data.sign()\n",
    "        if not self.bias is None:\n",
    "            gb = da*self.vector_b\n",
    "            gb = torch.mean(gb, dim = 0)\n",
    "            self.bias.data -= (lr*gb).view(-1)\n",
    "            self.bias.data = self.bias.data.sign()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "class self_Hardtanh(nn.Hardtanh):\n",
    "    def __init__(self, *kargs, **kwargs):\n",
    "        super(self_Hardtanh, self).__init__(*kargs, **kwargs)\n",
    "    \n",
    "    def forward(self, input, da):\n",
    "        new_da = da.clone()\n",
    "        new_da[input.expand_as(da)>1] = 0\n",
    "        new_da[input.expand_as(da)<-1] = 0\n",
    "        out = input.clamp(-1, 1)\n",
    "        return out, new_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "class self_batchnorm1d():\n",
    "    def __init__(self, dim):\n",
    "        self.dim = dim\n",
    "        self.BN = nn.BatchNorm1d(self.dim).to(DEVICE)\n",
    "    \n",
    "    def forward(self, input, da):\n",
    "        num_dir = da.shape[0]\n",
    "        self.vector_w = torch.randn((num_dir, self.BN.weight.data.shape[0]), device = DEVICE).sign()\n",
    "        self.vector_b = torch.randn((num_dir, self.BN.bias.data.shape[0]), device = DEVICE).sign()\n",
    "        new_da = torch.zeros(da.shape, device = DEVICE)\n",
    "        for i in range(num_dir):\n",
    "            with fwAD.dual_level():\n",
    "                dual_input = fwAD.make_dual(input, da[i])\n",
    "                dual_output = self.BN(dual_input)\n",
    "                jvp = fwAD.unpack_dual(dual_output).tangent\n",
    "                mid = (dual_output - self.BN.bias)/self.BN.weight\n",
    "                new_da[i] = jvp + mid*self.vector_w[i] + self.vector_b[i]\n",
    "        out = self.BN(input)\n",
    "        return out, new_da\n",
    "    \n",
    "    def update(self, da, lr):\n",
    "        gw = da.view(-1, 1)*self.vector_w\n",
    "        gw = torch.mean(gw, dim = 0)\n",
    "        self.BN.weight.data -= lr*gw\n",
    "        gb = da.view(-1, 1)*self.vector_b\n",
    "        gb = torch.mean(gb, dim = 0)\n",
    "        self.BN.bias.data -= lr*gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "class self_Softmax_CrossEntropy():\n",
    "    def __init__(self):\n",
    "        self.CE = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, input, da, y):\n",
    "        num_dir = da.shape[0]\n",
    "        new_da = torch.zeros(num_dir, device = DEVICE)\n",
    "        for i in range(num_dir):\n",
    "            with fwAD.dual_level():\n",
    "                dual_input = fwAD.make_dual(input, da[i])\n",
    "                dual_output = self.CE(dual_input, y)\n",
    "                jvp = fwAD.unpack_dual(dual_output).tangent\n",
    "                new_da[i] = jvp\n",
    "        \n",
    "        loss = self.CE(input, y)\n",
    "        return loss, new_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass self_Softmax_CrossEntropy():\\n    def forward(self, input, da, labels):\\n        exp_z = torch.exp(input)\\n        sum_exp_z = torch.sum(exp_z, dim=1).reshape(input.shape[0], 1)\\n        softmax_z = exp_z/sum_exp_z\\n        loss = torch.sum(-(labels*torch.log(softmax_z))) / input.shape[0]\\n        #new_da = torch.sum(da*(softmax_z - labels))/input.shape[0]\\n        new_da = torch.zeros([da.shape[0], 1, 1], dtype = float, device=DEVICE)\\n        for i in range(da.shape[0]):\\n            new_da[i] = torch.sum(da[i]*(softmax_z - labels))/input.shape[0]\\n        return loss, new_da\\n'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class self_Softmax_CrossEntropy():\n",
    "    def forward(self, input, da, labels):\n",
    "        exp_z = torch.exp(input)\n",
    "        sum_exp_z = torch.sum(exp_z, dim=1).reshape(input.shape[0], 1)\n",
    "        softmax_z = exp_z/sum_exp_z\n",
    "        loss = torch.sum(-(labels*torch.log(softmax_z))) / input.shape[0]\n",
    "        #new_da = torch.sum(da*(softmax_z - labels))/input.shape[0]\n",
    "        new_da = torch.zeros([da.shape[0], 1, 1], dtype = float, device=DEVICE)\n",
    "        for i in range(da.shape[0]):\n",
    "            new_da[i] = torch.sum(da[i]*(softmax_z - labels))/input.shape[0]\n",
    "        return loss, new_da\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMLP_1():\n",
    "    def __init__(self, device = DEVICE):\n",
    "        self.device = device\n",
    "\n",
    "        self.fc_1 = self_BinarizeLinear(28*28, 1024, bias=True, device = DEVICE)\n",
    "        self.htan_1 = self_Hardtanh()\n",
    "        self.bn_1 = self_batchnorm1d(1024)\n",
    "\n",
    "        self.fc_2 = self_BinarizeLinear(1024, 1024, bias=True, device = DEVICE)\n",
    "        self.htan_2 = self_Hardtanh()\n",
    "        self.bn_2 = self_batchnorm1d(1024)\n",
    "\n",
    "        self.fc_3 = self_BinarizeLinear(1024, 1024, bias=True, device = DEVICE)\n",
    "        self.htan_3 = self_Hardtanh()\n",
    "        self.bn_3 = self_batchnorm1d(1024)\n",
    "\n",
    "        self.fc_4 = self_BinarizeLinear(1024, 10, bias=True, device = DEVICE)\n",
    "        self.CrossEntropy = self_Softmax_CrossEntropy()\n",
    "    \n",
    "    def forward(self, input, labels, num_dir):\n",
    "        x = torch.reshape(input, (input.shape[0], 28*28))\n",
    "        da = None\n",
    "        x, da = self.fc_1(num_dir, x)\n",
    "        x, da = self.htan_1(x, da)\n",
    "        x, da = self.bn_1.forward(x, da)\n",
    "\n",
    "        x, da = self.fc_2(num_dir, x, da)\n",
    "        x, da = self.htan_2(x, da)\n",
    "        x, da = self.bn_2.forward(x, da)\n",
    "\n",
    "        x, da = self.fc_3(num_dir, x, da)\n",
    "        x, da = self.htan_3(x, da)\n",
    "        x, da = self.bn_3.forward(x, da)\n",
    "\n",
    "        x, da = self.fc_4(num_dir, x, da)\n",
    "        self.output = x\n",
    "        loss, da = self.CrossEntropy.forward(x, da, labels)\n",
    "        self.loss = loss\n",
    "        self.da = da.view(-1, 1, 1)\n",
    "    \n",
    "    def update(self, lr):\n",
    "        self.fc_1.update(self.da, lr)\n",
    "        self.fc_2.update(self.da, lr)\n",
    "        self.fc_3.update(self.da, lr)\n",
    "        self.fc_4.update(self.da, lr)\n",
    "        self.bn_1.update(self.da, lr)\n",
    "        self.bn_2.update(self.da, lr)\n",
    "        self.bn_3.update(self.da, lr)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, train_dl, valid_dl, test_dl, max_epochs = 20, lr = 1e-2, num_dir = 1):\n",
    "    itr = -1\n",
    "    stats = {'train-loss': [], 'valid-acc': []}\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        for X, y in train_dl:\n",
    "            itr += 1\n",
    "            #one_hot_y = torch.zeros(X.shape[0], 10).to(DEVICE)\n",
    "            #one_hot_y[[i for i in range(X.shape[0])], [k.item() for k in y]] = 1\n",
    "            model.forward(X, y, num_dir)\n",
    "            model.update(lr)\n",
    "            stats['train-loss'].append((itr, model.loss.item()))\n",
    "\n",
    "            if itr % 20 == 0:\n",
    "                valid_acc = get_acc(model, valid_dl, num_dir)\n",
    "                stats['valid-acc'].append((itr, valid_acc))\n",
    "                s = f\"{epoch}:{itr} [train] loss:{model.loss.item():.3f}, [valid] acc:{valid_acc:.3f}\"\n",
    "                print(s)\n",
    "    test_acc = get_acc(model, test_dl, num_dir)\n",
    "    print(f\"[test] acc:{test_acc:.3f}\")\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = 1024\n",
    "valid_batch = 1024\n",
    "\n",
    "model = BMLP_1()\n",
    "max_epochs = 200\n",
    "lr = 1e-1\n",
    "num_dir = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:0 [train] loss:51.492, [valid] acc:0.073\n",
      "0:20 [train] loss:52.000, [valid] acc:0.076\n",
      "0:40 [train] loss:52.041, [valid] acc:0.077\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/deyaoyux/Gitlab/forward-mode-bnn/True_BNN+True_Forward_Mode.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703031222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-bnn/True_BNN%2BTrue_Forward_Mode.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_dl, valid_dl, test_dl \u001b[39m=\u001b[39m get_mnist_dl(batch_size_train\u001b[39m=\u001b[39mtrain_batch, batch_size_eval\u001b[39m=\u001b[39mvalid_batch, device\u001b[39m=\u001b[39mDEVICE)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703031222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-bnn/True_BNN%2BTrue_Forward_Mode.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m stats \u001b[39m=\u001b[39m run_experiment(model, train_dl, valid_dl, test_dl, max_epochs, lr, num_dir)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703031222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-bnn/True_BNN%2BTrue_Forward_Mode.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m print_stats(stats)\n",
      "\u001b[1;32m/home/deyaoyux/Gitlab/forward-mode-bnn/True_BNN+True_Forward_Mode.ipynb Cell 15\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(model, train_dl, valid_dl, test_dl, max_epochs, lr, num_dir)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703031222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-bnn/True_BNN%2BTrue_Forward_Mode.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39mforward(X, y, num_dir)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703031222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-bnn/True_BNN%2BTrue_Forward_Mode.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m model\u001b[39m.\u001b[39mupdate(lr)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703031222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-bnn/True_BNN%2BTrue_Forward_Mode.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m stats[\u001b[39m'\u001b[39m\u001b[39mtrain-loss\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend((itr, model\u001b[39m.\u001b[39;49mloss\u001b[39m.\u001b[39;49mitem()))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703031222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-bnn/True_BNN%2BTrue_Forward_Mode.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mif\u001b[39;00m itr \u001b[39m%\u001b[39m \u001b[39m20\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226465737463307374726170703031222c2275736572223a22646579616f797578227d/home/deyaoyux/Gitlab/forward-mode-bnn/True_BNN%2BTrue_Forward_Mode.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     valid_acc \u001b[39m=\u001b[39m get_acc(model, valid_dl, num_dir)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl, test_dl = get_mnist_dl(batch_size_train=train_batch, batch_size_eval=valid_batch, device=DEVICE)\n",
    "stats = run_experiment(model, train_dl, valid_dl, test_dl, max_epochs, lr, num_dir)\n",
    "print_stats(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[18., 18., 18., 18.],\n",
      "        [25., 25., 25., 25.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd.forward_ad as fwAD\n",
    "\n",
    "primal_input = torch.tensor([[1.,2.,3.], [4.,5.,6.]])\n",
    "primal_weight = torch.ones(3,4)\n",
    "primal_bias = torch.tensor([1.,2.,3.,4.])\n",
    "tangent_input = torch.tensor([[2., 7., 2.], [3., 5., 1.]])\n",
    "tangent_weight = torch.ones(3, 4)\n",
    "tangent_bias = torch.ones(4)\n",
    "\n",
    "def fn(input, weight, bias):\n",
    "    return torch.matmul(input, weight) + bias\n",
    "\n",
    "# All forward AD computation must be performed in the context of\n",
    "# a ``dual_level`` context. All dual tensors created in such a context\n",
    "# will have their tangents destroyed upon exit. This is to ensure that\n",
    "# if the output or intermediate results of this computation are reused\n",
    "# in a future forward AD computation, their tangents (which are associated\n",
    "# with this computation) won't be confused with tangents from the later\n",
    "# computation.\n",
    "with fwAD.dual_level():\n",
    "    # To create a dual tensor we associate a tensor, which we call the\n",
    "    # primal with another tensor of the same size, which we call the tangent.\n",
    "    # If the layout of the tangent is different from that of the primal,\n",
    "    # The values of the tangent are copied into a new tensor with the same\n",
    "    # metadata as the primal. Otherwise, the tangent itself is used as-is.\n",
    "    #\n",
    "    # It is also important to note that the dual tensor created by\n",
    "    # ``make_dual`` is a view of the primal.\n",
    "    dual_input = fwAD.make_dual(primal_input, tangent_input)\n",
    "    dual_weight = fwAD.make_dual(primal_weight, tangent_weight)\n",
    "    dual_bias = fwAD.make_dual(primal_bias, tangent_bias)\n",
    "    # Tensors that do not not have an associated tangent are automatically\n",
    "    # considered to have a zero-filled tangent of the same shape.\n",
    "    dual_output = fn(dual_input, dual_weight, dual_bias)\n",
    "\n",
    "    # Unpacking the dual returns a namedtuple with ``primal`` and ``tangent``\n",
    "    # as attributes\n",
    "    jvp = fwAD.unpack_dual(dual_output).tangent\n",
    "\n",
    "assert fwAD.unpack_dual(dual_output).tangent is None\n",
    "print(jvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight\n",
      "torch.Size([1024])\n",
      "bias\n",
      "torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = nn.BatchNorm1d(1024)\n",
    "primal_input = torch.tensor([[1.,2.,3.], [4.,5.,6.]])\n",
    "tangent_input = torch.tensor([[2., 7., 2.], [3., 5., 1.]])\n",
    "\n",
    "params = {name: p for name, p in model.named_parameters()}\n",
    "\n",
    "with fwAD.dual_level():\n",
    "    for name, p in params.items():\n",
    "        print(name)\n",
    "        print(p.shape)\n",
    "        '''\n",
    "        if name == 'weight':\n",
    "            delattr(model, name)\n",
    "            p.data = torch.ones(4, 3)\n",
    "            setattr(model, name, fwAD.make_dual(p, torch.ones(4, 3)))\n",
    "            setattr(model, name, p)\n",
    "        else:\n",
    "            delattr(model, name)\n",
    "            p.data = torch.tensor([1.,2.,3.,4.])\n",
    "            setattr(model, name, fwAD.make_dual(p, torch.ones(4)))\n",
    "            setattr(model, name, p)\n",
    "    dual_input = fwAD.make_dual(primal_input, tangent_input)\n",
    "    #print(fwAD.unpack_dual(model.weight).primal)\n",
    "    #fwAD.unpack_dual(dual_input).tangent =torch.tensor([[2., 7., 2.], [3., 5., 2.]])\n",
    "    #print(dual_input)\n",
    "    out = model(primal_input)\n",
    "    jvp = fwAD.unpack_dual(out).tangent\n",
    "res = model(primal_input)\n",
    "print(model.weight)\n",
    "print(res)\n",
    "print(jvp)\n",
    "print(out)\n",
    "params = {name: p for name, p in model.named_parameters()}\n",
    "print(params)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = nn.Linear(10, 2)\n",
    "lin.weight.data[0][0] = 1.\n",
    "x = torch.randn(1, 10)\n",
    "output = lin(x)\n",
    "output.mean().backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('BNN': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb840f806f29f410adf72128552a18fefb24267895bb11ac579fa6a12231d74f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
